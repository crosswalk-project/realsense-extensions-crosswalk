<!DOCTYPE html>
<html>
  <head>
    <title>Face Tracking And Recognition</title>
    <meta charset='utf-8'>
    <script src='respec/respec-w3c-common.js'
            async class='remove'></script>
    <script class='remove'>
      var respecConfig = {
          // specification status (e.g. WD, LCWD, WG-NOTE, etc.). If in doubt use ED.
          specStatus:           "unofficial",

          additionalCopyrightHolders: "This document uses the BSD license, see the <a href='https://github.com/crosswalk-project/realsense-extensions-crosswalk/blob/master/LICENSE'>LICENSE</a> file.",

          shortName:            "face",
          // editors, add as many as you like
          // only "name" is required
          editors:  [
              {
                  name:       "Leon Han"
              ,   company:    "Intel"
              ,   companyURL: "http://www.intel.com/"
              },
          ],
      };
    </script>
  </head>
  <body>
    <section id='abstract'>
      <p>
        This specification describes support for accessing 3D camera for face tracking and recognition on the Web.
      </p>
    </section>

    <section id='sotd'>
      <p>
        This document was published by the <a href="https://crosswalk-project.org/">Crosswalk Project</a>
        as an API Draft.
        If you wish to make comments regarding this document, please send them to 
        <a href="mailto:crosswalk-dev@lists.crosswalk-project.org">crosswalk-dev@lists.crosswalk-project.org</a>.
        All comments are welcome.
      </p>
    </section>

    <section>
      <h2>Introduction</h2>
      <p>
        The APIs described in this document are exposed through
        <code>realsense.Face</code> module.
      </p>
    </section>
    <section>
      <h2>
        Interfaces
      </h2>
      <section>
        <h2>
          <code><a>FaceModule</a></code>
        </h2>
        <p>
          The <code><a>FaceModule</a></code> interface provides methods to
          track and recognize faces for augmented reality applications. 
        </p>
        <p>
          The <code>MediaStream</code> (described in [[!GETUSERMEDIA]]) passed
          to the constructor must have at least one video track otherwise an
          exception will be thrown.
        </p>
        <dl title='[Constructor(MediaStream stream)] interface FaceModule: EventTarget' class='idl'>
          <dt>
            Promise&lt;void&gt; start()
          </dt>
          <dd>
            <p>
            Start to run face module on the <code><a>previewStream</a></code> with current configuration.
            </p>
            <p>
              This method returns a promise.
              The promise will be fulfilled if there are no errors.
              The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
              Note: Please call this method after <code><a>ready</a></code> event,
              otherwise you will get a <code><a>ErrorEvent</a></code>.
            </p>
          </dd>
          <dt>
            Promise&lt;void&gt; stop()
          </dt>
          <dd>
            <p>
              Stop face module running and reset face configuration to defaults.
            </p>
            <p>
              This method returns a promise.
              The promise will be fulfilled if there are no errors.
              The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
            </p>
          </dd>
          <dt>
            Promise&lt;ProcessedSample&gt; getProcessedSample(optional boolean getColor, optional boolean getDepth)
          </dt>
          <dd>
            <p>
              Get processed sample including result face data along with processed color/depth image(optional).
            </p>
            <p>
              This method returns a promise.
              The promise will be fulfilled with an <code><a>ProcessedSample</a></code>
              combining color/depth processed images(only if required and available)
              and face module tracking/recognition output data if there are no errors.
              The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
            </p>
            <dl class='parameters'>
              <dt>optional boolean getColor</dt>
              <dd>
              <p>
                The flag to indicate whether want to aquire the color image data. The default value is false.
              </p>
              </dd>
              <dt>optional boolean getDepth</dt>
              <dd>
              <p>
                The flag to indicate whether want to aquire the depth image data. The default value is false.
              </p>
              </dd>
            </dl>
          </dd>
          <dt>
            readonly attribute FaceConfiguration configuration
          </dt>
          <dd>
            <p>
            The interface to configure <code><a>FaceModule</a></code>.
            </p>
          </dd>
          <dt>
            readonly attribute Recognition recognition
          </dt>
          <dd>
            <p>
              The interface to access face recognition feature.
            </p>
          </dd>
          <dt>
            readonly attribute MediaStream previewStream;
          </dt>
          <dd>
            <p>
              The <code>MediaStream</code> instance passed in constructor.
            </p>
          </dd>
          <dt>
            attribute EventHandler onready
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>Event</code></a> that is dispatched
              to <code><a>FaceModule</a></code> to indicate that it's ready to <code><a>start</a></code>
              because the <code><a>previewStream</a></code> has been started.
            </p>
          </dd>
          <dt>
            attribute EventHandler onended
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>Event</code></a> that is dispatched
              to <code><a>FaceModule</a></code> to indicate that the <code><a>previewStream</a></code> has ended
              and <code><a>FaceModule</a></code> has already detached from it completely.
            </p>
          </dd>
          <dt>
            attribute EventHandler onerror
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>ErrorEvent</code></a> that is dispatched
              to <code><a>FaceModule</a></code> when there is an error.
            </p>
          </dd>
          <dt>
            attribute EventHandler onprocessedsample
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>Event</code></a> that is dispatched
              to <code><a>FaceModule</a></code> when a new processed sample is ready.
            </p>
          </dd>
          <dt>
            attribute EventHandler onalert
          </dt>
          <dd>
            <p>
              A property used to set the EventHandler (described in [[!HTML]])
              for the <a><code>AlertEvent</code></a> that is dispatched
              to <code><a>FaceModule</a></code> when there is an alert happened.
            </p>
          </dd>
        </dl>
        <section>
          <h3>
            <code><a>AlertEvent</a></code> interface
          </h3>
          <dl class="idl" title="interface AlertEvent : Event">
            <dt>
              readonly attribute AlertType typeLabel
            </dt>
            <dd>
              <p>
                The label of the alert event.
              </p>
            </dd>
            <dt>
              readonly attribute long timeStamp
            </dt>
            <dd>
              <p>
                The time stamp when the event occurred, in 100ns.
              </p>
            </dd>
            <dt>
              readonly attribute long faceId
            </dt>
            <dd>
              <p>
                The identifier of the relevant face, if relevant and known.
              </p>
            </dd>
          </dl>
        </section>
        <section>
          <h3>
            <code><a>Recognition</a></code> interface
          </h3>
          <p>
            The <code><a>Recognition</a></code> interface provides methods to
            access face recognition feature.
          </p>
          <dl title='interface Recognition' class='idl'>
            <dt>
              Promise&lt;long&gt; registerUserByFaceID(long faceId)
            </dt>
            <dd>
              <p>
                Register a detected face into recognition database.
              </p>
              <p>
                This method returns a promise.
                The promise will be fulfilled with the user identifier
                registered in recognition database if there are no errors.
                The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
              </p>
              <dl class='parameters'>
                <dt>long faceId</dt>
                <dd>
                <p>
                  The face id which could be gotten
                  from the detected face data <code><a>FaceData</a></code>.
                </p>
                </dd>
              </dl>
            </dd>
            <dt>
              Promise&lt;void&gt; unregisterUserByID(long userId)
            </dt>
            <dd>
              <p>
                Unregister an user from recognition database.
              </p>
              <p>
                This method returns a promise.
                The promise will be fulfilled if there are no errors.
                The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
              </p>
              <dl class='parameters'>
                <dt>long userId</dt>
                <dd>
                <p>
                  The user identifier in recognition database,
                  could be gotten from the face recognition data <code><a>RecognitionData</a></code>
                  or the return value of the function <code>registerUserByFaceID</code>.
                </p>
                </dd>
              </dl>
            </dd>
          </dl>
        </section>
        <section>
          <h3>
            <code><a>FaceConfiguration</a></code> interface
          </h3>
          <p>
            The <code><a>FaceConfiguration</a></code> interface provides methods to
            configure <code><a>FaceModule</a></code>.
          </p>
          <dl title='interface FaceConfiguration' class='idl'>
            <dt>
              Promise&lt;void&gt; set(FaceConfigurationData config)
            </dt>
            <dd>
              <p>
                Set configuration values.
              </p>
              <p>
                This method returns a promise.
                The promise will be fulfilled if there are no errors.
                The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
              </p>
              <dl class='parameters'>
                <dt>FaceConfigurationData config</dt>
                <dd>
                <p>
                  The face configuration to be set effective.
                  Note: some configuration items won't take effect while face module is running,
                  such as <code><a>TrackingModeType</a></code>.
                  If you need to set it, please stop face module firstly.
                </p>
                </dd>
              </dl>
            </dd>
            <dt>
              Promise&lt;FaceConfigurationData&gt; getDefaults()
            </dt>
            <dd>
              <p>
                Get configuration default values.
              </p>
              <p>
                This method returns a promise.
                The promise will be fulfilled with the default face configuration
                if there are no errors.
                The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
              </p>
            </dd>
            <dt>
              Promise&lt;FaceConfigurationData&gt; get()
            </dt>
            <dd>
              <p>
                Get current effective configuration values.
              </p>
              <p>
                This method returns a promise.
                The promise will be fulfilled with current effective face configuration
                if there are no errors.
                The promise will be rejected with the <code><a>DOMException</a></code> object if there is a failure.
              </p>
            </dd>
          </dl>
        </section>
      </section>
    </section>
    <section>
      <h2>
        Dictionaries
      </h2>
      <section>
        <h2>
          <code><a>Image</a></code>
        </h2>
        <dl title='dictionary Image' class='idl'>
          <dt>
            PixelFormat format
          </dt>
          <dd>
          </dd>
          <dt>
            long width
          </dt>
          <dd>
          </dd>
          <dt>
            long height
          </dt>
          <dd>
          </dd>
          <dt>
            ArrayBuffer data
          </dt>
          <dd>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Rect</a></code>
        </h2>
        <dl title='dictionary Rect' class='idl'>
          <dt>
            long x
          </dt>
          <dd>
          </dd>
          <dt>
            long y
          </dt>
          <dd>
          </dd>
          <dt>
            long w
          </dt>
          <dd>
          </dd>
          <dt>
            long h
          </dt>
          <dd>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Point3DFloat</a></code>
        </h2>
        <dl title='dictionary Point3DFloat' class='idl'>
          <dt>
            double x
          </dt>
          <dd>
          </dd>
          <dt>
            double y
          </dt>
          <dd>
          </dd>
          <dt>
            double z
          </dt>
          <dd>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>Point2DFloat</a></code>
        </h2>
        <dl title='dictionary Point2DFloat' class='idl'>
          <dt>
            double x
          </dt>
          <dd>
          </dd>
          <dt>
            double y
          </dt>
          <dd>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>AlertConfiguration</a></code>
        </h2>
        <dl title='dictionary AlertConfiguration' class='idl'>
          <dt>
            boolean? newFaceDetected
          </dt>
          <dd>
            Enable new_face_detected alert.
          </dd>
          <dt>
            boolean? faceOutOfFov
          </dt>
          <dd>
            Enable face_out_of_fov alert.
          </dd>
          <dt>
            boolean? faceBackToFov
          </dt>
          <dd>
            Enable face_back_to_fov alert.
          </dd>
          <dt>
            boolean? faceOccluded
          </dt>
          <dd>
            Enable face_occluded alert.
          </dd>
          <dt>
            boolean? faceNoLongerOccluded
          </dt>
          <dd>
            Enable face_no_longer_occluded alert.
          </dd>
          <dt>
            boolean? faceLost
          </dt>
          <dd>
            Enable face_lost alert.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>DetectionConfiguration</a></code>
        </h2>
        <dl title='dictionary DetectionConfiguration' class='idl'>
          <dt>
            boolean? enable
          </dt>
          <dd>
            Enable face detection feature.
          </dd>
          <dt>
            long? maxFaces
          </dt>
          <dd>
            Maximum number of faces to be tracked.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>LandmarksConfiguration</a></code>
        </h2>
        <dl title='dictionary LandmarksConfiguration' class='idl'>
          <dt>
            boolean? enable
          </dt>
          <dd>
            Enable face landmarks feature.
          </dd>
          <dt>
            long? maxFaces
          </dt>
          <dd>
            Maximum number of faces to be tracked.
          </dd>
          <dt>
            long? numLandmarks
          </dt>
          <dd>
            Maximum number of landmarks to be tracked.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>RecognitionConfiguration</a></code>
        </h2>
        <dl title='dictionary RecognitionConfiguration' class='idl'>
          <dt>
            boolean? enable
          </dt>
          <dd>
            Enable face recognition feature.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>FaceConfigurationData</a></code>
        </h2>
        <dl title='dictionary FaceConfigurationData' class='idl'>
          <dt>
            TrackingModeType? mode
          </dt>
          <dd>
            Face tracking input data modes.
          </dd>
          <dt>
            TrackingStrategyType? strategy
          </dt>
          <dd>
            Face tracking strategy.
          </dd>
          <dt>
            AlertConfiguration? alert
          </dt>
          <dd>
            <p>
              The structure describing the alert enable/disable status.
            </p>
          </dd>
          <dt>
            DetectionConfiguration? detection
          </dt>
          <dd>
            <p>
              The structure describing the face detection configuration parameters.
            </p>
          </dd>
          <dt>
            LandmarksConfiguration? landmarks
          </dt>
          <dd>
            <p>
              The structure describing the face landmarks configuration parameters.
            </p>
          </dd>
          <dt>
            RecognitionConfiguration? recognition
          </dt>
          <dd>
            <p>
              The structure describing the face recognition configuration parameters.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>DetectionData</a></code>
        </h2>
        <dl title='dictionary DetectionData' class='idl'>
          <dt>
            Rect boundingRect
          </dt>
          <dd>
            The bounding box of the detected face.
          </dd>
          <dt>
            double avgDepth
          </dt>
          <dd>
            The average depth of the detected face.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>LandmarkPoint</a></code>
        </h2>
        <dl title='dictionary LandmarkPoint' class='idl'>
          <dt>
            LandmarkType type
          </dt>
          <dd>
            Landmark point type.
          </dd>
          <dt>
            long confidenceImage
          </dt>
          <dd>
            The confidence score from 0 to 100 of the image coordinates.
          </dd>
          <dt>
            long confidenceWorld
          </dt>
          <dd>
            The confidence score from 0 to 100 of the world coordinates.
          </dd>
          <dt>
            Point3DFloat coordinateWorld
          </dt>
          <dd>
            The world coordinates of the landmark point.
          </dd>
          <dt>
            Point2DFloat coordinateImage
          </dt>
          <dd>
            The color image coordinates of the landmark point.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>LandmarksData</a></code>
        </h2>
        <dl title='dictionary LandmarksData' class='idl'>
          <dt>
            sequence&lt;LandmarkPoint&gt; points
          </dt>
          <dd>
            All landmark points of the detected face.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>RecognitionData</a></code>
        </h2>
        <dl title='dictionary RecognitionData' class='idl'>
          <dt>
            long userId
          </dt>
          <dd>
            The user identifier in the recognition database.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>FaceData</a></code>
        </h2>
        <dl title='dictionary FaceData' class='idl'>
          <dt>
            long? faceId
          </dt>
          <dd>
            ID of the detected face.
          </dd>
          <dt>
            DetectionData? detection
          </dt>
          <dd>
            Detection data of the detected face.
          </dd>
          <dt>
            LandmarksData? landmarks
          </dt>
          <dd>
            Landmarks data of the detected face.
          </dd>
          <dt>
            RecognitionData? recognition
          </dt>
          <dd>
            Recognition result data of the detected face.
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>ProcessedSample</a></code>
        </h2>
        <dl title='dictionary ProcessedSample' class='idl'>
          <dt>
            Image? color
          </dt>
          <dd>
            Color stream image.
          </dd>
          <dt>
            Image? depth
          </dt>
          <dd>
            Depth stream image.
          </dd>
          <dt>
            sequence&lt;FaceData&gt; faces
          </dt>
          <dd>
            All the detected faces.
          </dd>
        </dl>
      </section>
    </section>
    <section>
      <h2>
        Enumerators
      </h2>
      <section>
        <h2>
          <code><a>TrackingModeType</a></code> enum
        </h2>
        <dl id="enum-basic" class="idl" title="enum TrackingModeType">
          <dt>
            color 
          </dt>
          <dd>
            <p>
              Require color data at the module input to run face algorithms.
            </p>
          </dd>
          <dt>
            color-depth
          </dt>
          <dd>
            <p>
              Require color and depth data at the module input to run face algorithms.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>TrackingStrategyType</a></code> enum
        </h2>
        <dl id="enum-basic" class="idl" title="enum TrackingStrategyType">
          <dt>
            appearance-time
          </dt>
          <dd>
            <p>
              Track faces based on their appearance in the scene.
            </p>
          </dd>
          <dt>
            closest-farthest
          </dt>
          <dd>
            <p>
              Track faces from the closest to the furthest.
            </p>
          </dd>
          <dt>
            farthest-closest
          </dt>
          <dd>
            <p>
              Track faces from the furthest to the closest.
            </p>
          </dd>
          <dt>
            left-right
          </dt>
          <dd>
            <p>
              Track faces from left to right.
            </p>
          </dd>
          <dt>
            right-left
          </dt>
          <dd>
            <p>
              Track faces from right to left.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>AlertType</a></code> enum
        </h2>
        <dl id="enum-basic" class="idl" title="enum AlertType">
          <dt>
            new-face-detected
          </dt>
          <dd>
            <p>
              A new face enters the FOV and its position and bounding rectangle is available.
            </p>
          </dd>
          <dt>
            face-out-of-fov
          </dt>
          <dd>
            <p>
              A new face is out of field of view (even slightly).
            </p>
          </dd>
          <dt>
            face-back-to-fov
          </dt>
          <dd>
            <p>
              A tracked face is back fully to field of view.
            </p>
          </dd>
          <dt>
            face-occluded
          </dt>
          <dd>
            <p>
              Face is occluded by any object or hand (even slightly).
            </p>
          </dd>
          <dt>
            face-no-longer-occluded
          </dt>
          <dd>
            <p>
              Face is not occluded by any object or hand.
            </p>
          </dd>
          <dt>
            face-lost
          </dt>
          <dd>
            <p>
              A face could not be detected for too long, will be ignored.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>PixelFormat</a></code> enum
        </h2>
        <dl id="enum-basic" class="idl" title="enum PixelFormat">
          <dt>
            rgb32
          </dt>
          <dd>
            <p>
              The 32-bit RGB32 color format.
            </p>
          </dd>
          <dt>
            depth
          </dt>
          <dd>
            <p>
              The depth map data in 16-bit unsigned integer.
            </p>
          </dd>
        </dl>
      </section>
      <section>
        <h2>
          <code><a>LandmarkType</a></code> enum
        </h2>
        <dl id="enum-basic" class="idl" title="enum LandmarkType">
          <dt>
            not-named
          </dt>
          <dd>
            <p>
              Unspecified.
            </p>
          </dd>
          <dt>
            eye-right-center
          </dt>
          <dd>
            <p>
              The center of the right eye.
            </p>
          </dd>
          <dt>
            eye-left-center,
          </dt>
          <dd>
            <p>
              The center of the left eye.
            </p>
          </dd>
          <dt>
            eyelid-right-top,
          </dt>
          <dd>
            <p>
              The right eye lid top.
            </p>
          </dd>
          <dt>
            eyelid-right-bottom,
          </dt>
          <dd>
            <p>
              The right eye lid bottom.
            </p>
          </dd>
          <dt>
            eyelid-right-right,
          </dt>
          <dd>
            <p>
              The right eye lid right.
            </p>
          </dd>
          <dt>
            eyelid-right-left,
          </dt>
          <dd>
            <p>
              The right eye lid left.
            </p>
          </dd>
          <dt>
            eyelid-left-top,
          </dt>
          <dd>
            <p>
              The left eye lid top.
            </p>
          </dd>
          <dt>
            eyelid-left-bottom,
          </dt>
          <dd>
            <p>
              The left eye lid bottom.
            </p>
          </dd>
          <dt>
            eyelid-left-right,
          </dt>
          <dd>
            <p>
              The left eye lid right.
            </p>
          </dd>
          <dt>
            eyelid-left-left,
          </dt>
          <dd>
            <p>
              The left eye lid left.
            </p>
          </dd>
          <dt>
            eyebrow-right-center,
          </dt>
          <dd>
            <p>
              The right eye brow center.
            </p>
          </dd>
          <dt>
            eyebrow-right-right,
          </dt>
          <dd>
            <p>
              The right eye brow right.
            </p>
          </dd>
          <dt>
            eyebrow-right-left,
          </dt>
          <dd>
            <p>
              The right eye brow left.
            </p>
          </dd>
          <dt>
            eyebrow-left-center,
          </dt>
          <dd>
            <p>
              The left eye brow center.
            </p>
          </dd>
          <dt>
            eyebrow-left-right,
          </dt>
          <dd>
            <p>
              The left eye brow right.
            </p>
          </dd>
          <dt>
            eyebrow-left-left,
          </dt>
          <dd>
            <p>
              The left eye brow left.
            </p>
          </dd>
          <dt>
            nose-tip,
          </dt>
          <dd>
            <p>
              The top most point of the nose in the Z dimension.
            </p>
          </dd>
          <dt>
            nose-top,
          </dt>
          <dd>
            <p>
              The nose top.
            </p>
          </dd>
          <dt>
            nose-bottom,
          </dt>
          <dd>
            <p>
              The nose bottom. 
            </p>
          </dd>
          <dt>
            nose-right,
          </dt>
          <dd>
            <p>
              The nose right. 
            </p>
          </dd>
          <dt>
            nose-left,
          </dt>
          <dd>
            <p>
              The nose left. 
            </p>
          </dd>
          <dt>
            lip-right,
          </dt>
          <dd>
            <p>
              The lip right. 
            </p>
          </dd>
          <dt>
            lip-left,
          </dt>
          <dd>
            <p>
              The lip left. 
            </p>
          </dd>
          <dt>
            upper-lip-center,
          </dt>
          <dd>
            <p>
              The lip center. 
            </p>
          </dd>
          <dt>
            upper-lip-right,
          </dt>
          <dd>
            <p>
              The lip upper right. 
            </p>
          </dd>
          <dt>
            upper-lip-left,
          </dt>
          <dd>
            <p>
              The lip upper left. 
            </p>
          </dd>
          <dt>
            lower-lip-center,
          </dt>
          <dd>
            <p>
              The lip lower center. 
            </p>
          </dd>
          <dt>
            lower-lip-right,
          </dt>
          <dd>
            <p>
              The lip lower right. 
            </p>
          </dd>
          <dt>
            lower-lip-left,
          </dt>
          <dd>
            <p>
              The lip lower left. 
            </p>
          </dd>
          <dt>
            face-border-top-right,
          </dt>
          <dd>
            <p>
              The face border right. 
            </p>
          </dd>
          <dt>
            face-border-top-left,
          </dt>
          <dd>
            <p>
              The face border left. 
            </p>
          </dd>
          <dt>
            chin
          </dt>
          <dd>
            <p>
              The bottom chin point. 
            </p>
          </dd>
        </dl>
      </section>
    </section>
    <section class='informative'>
      <h2>
        Examples
      </h2>
      <section>
        <h3>
          Start/Stop face module
        </h3>
        <pre class='example highlight'>
          var previewStream;
          var ft;
          var startButton = document.getElementById('startButton');
          var stopButton = document.getElementById('stopButton');

          function errorCallback(error) {
            console.log('getUserMedia failed: ' + error); 
          }

          // Start stream firstly, then start face module.
          startButton.onclick = function(e) {
            navigator.mediaDevices.getUserMedia(constraints)
                .then(function(stream) {
                  // Wire the media stream into a &lt;video&gt; element for preview.
                  previewStream = stream;
                  var previewVideo = document.querySelector('#previewVideo');
                  previewVideo.srcObject = stream;
                  previewVideo.play();

                  try {
                    ft = new realsense.Face.FaceModule(stream);
                  } catch (e) {
                    console.log('Failed to create face module: ' + e.message);
                    return;
                  }

                  ft.onready = function(e) {
                    console.log('Face module ready to start');
                    // The stream got ready, we can start face module now.
                    ft.start().then(
                        function() {
                          console.log('Face module start succeeds');},
                        function(e) {
                          console.log('Face module start failed: ' + e.message);}); 
                  };

                  ft.onprocessedsample = function(e) {
                    console.log('Got face module processedsample event.');
                    ft.getProcessedSample(false, false).then(function(processedSample) {
                      console.log('Got face module processedsample data.');
                      // Use processedSample.faces data to work for you.
                      console.log('Detected faces number: ' + processedSample.faces.length);
                      // You can get all avaiable detection/landmarks/recognition data
                      // of every face from processedSample.faces.
                      // Please refer to <code><a>FaceData</a></code> interface.
                    }, function(e) {
                      console.log('Failed to get processed sample: ' + e.message);});
                  };

                  ft.onerror = function(e) {
                    console.log('Got face module error event: ' + e.message);
                  };

                  ft.onended = function(e) {
                    console.log('Face module ends without stop');
                  };

                  ft.ready = false;
                  ftStarted = false;
                  onGetConfButton();
                }, errorCallback);
          };

          function stopPreviewStream() {
            if (previewStream) {
              previewStream.getTracks().forEach(function(track) {
                track.stop();
              });
              if (ft) {
                // Remove listeners as we don't care about the events.
                ft.onerror = null;
                ft.onprocessedsample = null;
                ft = null;
              }
            }
            previewStream = null;
          }

          // Stop face module and stream.
          stopButton.onclick = function(e) {
            if (!ft) return;
            ft.stop().then(
                function() {
                  console.log('Face module stop succeeds');
                  stopPreviewStream();},
                function(e) {
                  console.log('Face module stop failed');
                  stopPreviewStream();});
          };
        </pre>
      </section>
      <section>
        <h3>
          Face module configuration.
        </h3>
        <pre class='example highlight'>
          var setConfButton = document.getElementById('setConfButton');
          var getConfButton = document.getElementById('getConfButton');
          var getDefaultConfButton = document.getElementById('getDefaultConfButton');

          // Set configuration. Simple configuration example as bellow.
          // Please refer to <code><a>FaceConfigurationData</a></code> interface for confData details.
          var confData = {
            // Set face tracking strategy.
            strategy: 'right-left',
            // Disable landmarks.
            landmarks: {
              enable: false
            }, 
            // Enable recognition.
            recognition: {
              enable: true
            }
          };
          setConfButton.onclick = function(e) {
            ft.configuration.set(confData).then(
                function() {
                  console.log('set configuration succeeds');},
                function(e) {
                  console.log(e.message);});
          };

          // Get current configuration.
          getConfButton.onclick = function(e) {
            ft.configuration.get().then(
                function(confData) {
                  // Use confData values to work for you.
                  console.log('get current configuration succeeds');},
                function(e) {
                  console.log('get configuration failed: ' + e.message);});
          };

          // Get default configuration.
          getDefaultConfButton.onclick = function(e) {
            ft.configuration.getDefaults().then(
                function(confData) {
                  // Use confData values to work for you.
                  console.log('get default configuration succeeds');},
                function(e) {
                  console.log('get default configuration failed: ' + e.message);});
          };
        </pre>
      </section>
    </section>
    <section class='appendix'>
      <h2>Acknowledgements</h2>
      <p>
      </p>
    </section>
  </body>
</html>
